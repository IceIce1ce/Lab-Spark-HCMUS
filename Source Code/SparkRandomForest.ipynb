{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparkRandomForest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzH8v95zSmjD"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tY9HKldlS6Xm",
        "outputId": "f3642adc-66ed-4ce7-f064-a4238498aed8"
      },
      "source": [
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi5dNqkhTHo9"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34-SZjCZTIlb",
        "outputId": "8ea2954a-9097-4f1d-a294-d4118046817d"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "df = spark.sql(\"select 'spark' as hello \")\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|spark|\n",
            "+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HphVRW54TPRv",
        "outputId": "efce583e-8060-40b6-c66c-25382fa37279"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.python.pyspark.shell import spark\n",
        "\n",
        "# read input and show\n",
        "df = spark.read.options(delimiter=',', header=True).csv('/content/Absenteeism_at_work.csv')\n",
        "df = df.withColumn(\"MOA\", df[\"Month of absence\"] - 0).withColumn(\"label\", df['Transportation expense'] - 0).withColumn(\"ROA\", df[\"Reason for absence\"] - 0).\\\n",
        "    withColumn(\"distance\", df[\"Distance from Residence to Work\"] - 0).withColumn(\"BMI\", df[\"Body mass index\"] - 0)\n",
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+----------------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+---+-----+----+--------+----+\n",
            "| ID|Reason for absence|Month of absence|Day of the week|Seasons|Transportation expense|Distance from Residence to Work|Service time|Age|Work load Average/day |Hit target|Disciplinary_failure|Education|Son|Social drinker|Social smoker|Pet|Weight|Height|Body mass index|Absenteeism_time_in_hours|MOA|label| ROA|distance| BMI|\n",
            "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+----------------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+---+-----+----+--------+----+\n",
            "| 11|                26|               7|              3|      1|                   289|                             36|          13| 33|               239.554|        97|                   0|        1|  2|             1|            0|  1|    90|   172|             30|                        4|7.0|289.0|26.0|    36.0|30.0|\n",
            "| 36|                 0|               7|              3|      1|                   118|                             13|          18| 50|               239.554|        97|                   1|        1|  1|             1|            0|  0|    98|   178|             31|                        0|7.0|118.0| 0.0|    13.0|31.0|\n",
            "|  3|                23|               7|              4|      1|                   179|                             51|          18| 38|               239.554|        97|                   0|        1|  0|             1|            0|  0|    89|   170|             31|                        2|7.0|179.0|23.0|    51.0|31.0|\n",
            "|  7|                 7|               7|              5|      1|                   279|                              5|          14| 39|               239.554|        97|                   0|        1|  2|             1|            1|  0|    68|   168|             24|                        4|7.0|279.0| 7.0|     5.0|24.0|\n",
            "| 11|                23|               7|              5|      1|                   289|                             36|          13| 33|               239.554|        97|                   0|        1|  2|             1|            0|  1|    90|   172|             30|                        2|7.0|289.0|23.0|    36.0|30.0|\n",
            "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+----------------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+---+-----+----+--------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_0AC_cAUaUX",
        "outputId": "82fe78d4-9934-4e06-a497-d684c0f97fd0"
      },
      "source": [
        "# combine column label and distance to new column name features\n",
        "# https://spark.apache.org/docs/latest/ml-features#vectorindexer\n",
        "merge_col = VectorAssembler(inputCols=[\"label\", \"distance\"], outputCol='features')\n",
        "df = merge_col.transform(df)\n",
        "df.select(\"features\").show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+\n",
            "|    features|\n",
            "+------------+\n",
            "|[289.0,36.0]|\n",
            "|[118.0,13.0]|\n",
            "|[179.0,51.0]|\n",
            "| [279.0,5.0]|\n",
            "|[289.0,36.0]|\n",
            "+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA8v4UzbUyoD"
      },
      "source": [
        "# create a column indexedLabel mark label with most frequency start from 0.0 (most frequency) to n(least frequency)\n",
        "labelIndexerFrequency = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(df)\n",
        "# use transform(df) to show, not use when run\n",
        "# labelIndexerFrequency = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(df).transform(df)\n",
        "# labelIndexerFrequency.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwlRoox1U4mp"
      },
      "source": [
        "#decide which features should be treated as categorical\n",
        "featureIndexerFrequency = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1IDtgzLU8He",
        "outputId": "3d4c8583-5f01-44d9-9cb9-6b13b31678f2"
      },
      "source": [
        "# https://stackoverflow.com/questions/44981407/pyspark-ml-how-to-save-pipeline-and-randomforestclassificationmodel\n",
        "# split to 70-30\n",
        "(trainingData, testData) = df.randomSplit([0.7, 0.3])\n",
        "# Train a RandomForest model.\n",
        "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n",
        "# Convert indexed labels back to original labels.\n",
        "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexerFrequency.labels)\n",
        "# Chain indexers and tree in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexerFrequency, featureIndexerFrequency, rf, labelConverter])\n",
        "# Train model. This also runs the indexers.\n",
        "model = pipeline.fit(trainingData)\n",
        "# Make predictions.\n",
        "predictions = model.transform(testData)\n",
        "# Select example rows to display.\n",
        "predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n",
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Decision Tree - Test Accuracy = %g\" % (accuracy))\n",
        "print(\"Decision Tree - Test Error = %g\" % (1.0 - accuracy))\n",
        "rfModel = model.stages[2]\n",
        "print(rfModel) # summary only"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+-----+------------+\n",
            "|predictedLabel|label|    features|\n",
            "+--------------+-----+------------+\n",
            "|         235.0|235.0|[235.0,11.0]|\n",
            "|         235.0|235.0|[235.0,11.0]|\n",
            "|         235.0|235.0|[235.0,11.0]|\n",
            "|         235.0|235.0|[235.0,11.0]|\n",
            "|         235.0|235.0|[235.0,11.0]|\n",
            "+--------------+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Decision Tree - Test Accuracy = 0.940171\n",
            "Decision Tree - Test Error = 0.0598291\n",
            "RandomForestClassificationModel: uid=RandomForestClassifier_9bf8dc19afca, numTrees=10, numClasses=24, numFeatures=2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIILGrXnWr4U"
      },
      "source": [
        "# save model\n",
        "rfModel.save('/content/myModel')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}