{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparkNaiveBayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFtuw79BKsfV"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H69yYiz3LCxP"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgQnhY02LGxm"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxFYmcrqLjLE",
        "outputId": "3f100bb1-8cb9-4171-cf44-8be57e033917"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "df = spark.sql(\"select 'spark' as hello \")\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|spark|\n",
            "+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPqEHFlgLHe9",
        "outputId": "87722385-4735-45ca-e773-31f19c73f138"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 72kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 35.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=535e9c3ecea2e69d4b828d204ecc8d744fef92eb224d8b52358343b57f80af7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbyBErRULUGT",
        "outputId": "d7004b0e-5ee2-478d-a9f2-f79aac8e0846"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "import numpy as np\n",
        "import scipy\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.linalg import SparseVector\n",
        "\n",
        "#read input and show\n",
        "df = spark.read.options(delimiter=',', header=True).csv('/content/Absenteeism_at_work.csv')\n",
        "df = df.withColumn(\"MOA\", df[\"Month of absence\"] - 0).withColumn(\"label\", df['Seasons'] - 0).withColumn(\"ROA\", df[\"Reason for absence\"] - 0).\\\n",
        "    withColumn(\"distance\", df[\"Distance from Residence to Work\"] - 0).withColumn(\"BMI\", df[\"Body mass index\"] - 0)\n",
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+----------------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+---+-----+----+--------+----+\n",
            "| ID|Reason for absence|Month of absence|Day of the week|Seasons|Transportation expense|Distance from Residence to Work|Service time|Age|Work load Average/day |Hit target|Disciplinary_failure|Education|Son|Social drinker|Social smoker|Pet|Weight|Height|Body mass index|Absenteeism_time_in_hours|MOA|label| ROA|distance| BMI|\n",
            "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+----------------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+---+-----+----+--------+----+\n",
            "| 11|                26|               7|              3|      1|                   289|                             36|          13| 33|               239.554|        97|                   0|        1|  2|             1|            0|  1|    90|   172|             30|                        4|7.0|  1.0|26.0|    36.0|30.0|\n",
            "| 36|                 0|               7|              3|      1|                   118|                             13|          18| 50|               239.554|        97|                   1|        1|  1|             1|            0|  0|    98|   178|             31|                        0|7.0|  1.0| 0.0|    13.0|31.0|\n",
            "|  3|                23|               7|              4|      1|                   179|                             51|          18| 38|               239.554|        97|                   0|        1|  0|             1|            0|  0|    89|   170|             31|                        2|7.0|  1.0|23.0|    51.0|31.0|\n",
            "|  7|                 7|               7|              5|      1|                   279|                              5|          14| 39|               239.554|        97|                   0|        1|  2|             1|            1|  0|    68|   168|             24|                        4|7.0|  1.0| 7.0|     5.0|24.0|\n",
            "| 11|                23|               7|              5|      1|                   289|                             36|          13| 33|               239.554|        97|                   0|        1|  2|             1|            0|  1|    90|   172|             30|                        2|7.0|  1.0|23.0|    36.0|30.0|\n",
            "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+----------------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+---+-----+----+--------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_jihCI1MKDJ",
        "outputId": "faad79b1-5b82-47db-ee09-b3cf47c9e8ce"
      },
      "source": [
        "#combine column label and distance to new column name features\n",
        "#https://spark.apache.org/docs/latest/ml-features#vectorindexer\n",
        "merge_col = VectorAssembler(inputCols=[\"label\", \"MOA\"], outputCol='features')\n",
        "df = merge_col.transform(df)\n",
        "df.select(\"features\").show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "| features|\n",
            "+---------+\n",
            "|[1.0,7.0]|\n",
            "|[1.0,7.0]|\n",
            "|[1.0,7.0]|\n",
            "|[1.0,7.0]|\n",
            "|[1.0,7.0]|\n",
            "+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEia9QvmMTqC",
        "outputId": "053b356a-619c-422f-db31-ae3789a4be6c"
      },
      "source": [
        "#split 70, 30\n",
        "(trainingData, testData) = df.randomSplit([0.7, 0.3], 1000)\n",
        "#make the prediction\n",
        "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
        "#train the model\n",
        "model = nb.fit(trainingData)\n",
        "#select example rows to display\n",
        "predictions = model.transform(testData)\n",
        "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
        "#compute accuracy on the test set\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Naive Bayes - Test Accuracy = %g\" % (accuracy))\n",
        "print(\"Naive Bayes - Test Error = %g\" % (1.0 - accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+----------+\n",
            "|prediction|label|  features|\n",
            "+----------+-----+----------+\n",
            "|       1.0|  2.0| [2.0,1.0]|\n",
            "|       3.0|  4.0|[4.0,11.0]|\n",
            "|       0.0|  1.0| [1.0,8.0]|\n",
            "|       3.0|  4.0|[4.0,12.0]|\n",
            "|       0.0|  1.0| [1.0,8.0]|\n",
            "+----------+-----+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Naive Bayes - Test Accuracy = 0.0612245\n",
            "Naive Bayes - Test Error = 0.938776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7M6LFq6PvX0"
      },
      "source": [
        "#save model\n",
        "model.save('/content/myModel')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}